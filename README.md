# deep-learning
I study deep learning at weekly seminars. I set up my study articles and their training process in this repository. Useful Information About Deep Learning


##  article: Dropout: A Simple Way to Prevent Neural Networks from Overfitting <br> [article](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)
###### Definition of overfitting:Overfitting in Machine Learning. Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data
###### regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.
####  I watched the fifth part of [Dr. Mohammad Ali Keivan Rad's teaching]( https://www.aparat.com/v/ro9BQ) and Course slides and references can be found on the [course site](http://ceit.aut.ac.ir/~keyvanrad/DL961.html)
####  I suggest watching this movie for an [initial introduction to the topics Deep learning and Programming](http://fdrs.ir/qiqz)
###  [A useful site for Deep learning](https://cs.stanford.edu/people/karpathy/convnetjs/)
###  See examples of convolution in images on this [site](http://aishack.in/tutorials/image-convolution-examples/)
###  Complete training for [optimization algorithms in Deep learning](http://ruder.io/optimizing-gradient-descent/)
[towarddatascince](https://towardsdatascience.com/)
<br>
## article: Wasserstein GAN <br> [article](https://arxiv.org/abs/1701.07875) <br>
and [wassersteain dissertation](https://arxiv.org/pdf/1806.11382.pdf)
